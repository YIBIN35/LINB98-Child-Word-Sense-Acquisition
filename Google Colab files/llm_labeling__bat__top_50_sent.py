# -*- coding: utf-8 -*-
"""LLM Labeling "Bat" - Top 50 Sent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QlGbN0Oo-GPJvhNJ5Q9ADiNuauXVY1tZ
"""

import pandas as pd
import openai
import json

def label_with_LLM(df, definitions, sentence_col = "sentences", model = "gpt-4o-mini"):
  results = []
  def_processed = "\n".join(f"{key}: {value}" for key, value in definitions.items())

  for idx, row in df.iterrows():
    sentence = row[sentence_col]

    prompt = (
        "You are a word definition classifier. Based on the sentences and available definitions, "
        "choose the best-fitting definition and assign a confidence score.\n\n"
        f"Sentence index: {idx}\n"
        f"Sentence: {sentence}\n\n"
        f"Definitions:\n{def_processed}\n\n"
        "Return the result as a JSON object with EXACTLY the following structure:\n"
        "{\n"
        '  "sentence": "<the full sentence>",\n'
        '  "definition_key": "<the chosen definition key>",\n'
        '  "definition": "<the chosen definition text>",\n'
        '  "confidence": <number between 0 and 1>\n'
        "}\n\n"
        "Return ONLY valid JSON. "
        "Do NOT wrap your answer in a code block. "
        "Do NOT include ```json or any backticks. "
        "Your response must start with '{' and end with '}'. "
        "Any extra text makes the answer invalid."
      )

    resp = openai.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
        )

    content = resp.choices[0].message.content.strip()
    print("RAW OUTPUT:\n", content)
    parsed = json.loads(content)
    results.append(parsed)

  return pd.DataFrame(results)

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/MyDrive/sentence_data_bert_dpgmm100k_wordsetlarge_mixedSentFalse_pca2d_priorNone.csv"
pre_df = pd.read_csv(path)

df = pre_df[["target", "sentences", "sense_label", "distance_to_sense_mean"]]
df_bat = df[df["target"] == "bat"].copy()
df_sorted = df_bat.sort_values(by=["sense_label", "distance_to_sense_mean"])
top50_per_cluster = df_sorted.groupby("sense_label").head(50)

print(top50_per_cluster.shape)
print(top50_per_cluster['sense_label'].value_counts())

print(df_sorted["sense_label"].value_counts())

print(top50_per_cluster.head(10))

import getpass
openai.api_key = getpass.getpass("Enter API key:")

bat_glosses = {
    "def_1": "A bat is something we use to hit the ball in baseball or other sports. In baseball, the bat is made of wood or metal.",
    "def_2": "When you bat in the game of baseball, you have a chance to hit the ball.",
    "def_3": "	A bat is a small mammal that can fly. Bats have wings that are much longer than their bodies. They usually fly at night, and they eat many, many insects."
}

LLM_label = label_with_LLM(top50_per_cluster, bat_glosses)

LLM_label.to_csv("LLM_label_output.csv", index=False)

print(top50_per_cluster[["sentences", "sense_label"]].head(10))

# Manually checked, the sentences in the dataframe generated should have the same order
# as the original input dataframe, so every 20 sentences belong in the same cluster

LLM_label.columns

# Generate the histograms
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick

# Cluster 1
cluster_1 = LLM_label[:50]

counts = cluster_1["definition_key"].value_counts()

plt.figure(figsize=(6, 4))
plt.gca().yaxis.set_major_locator(mtick.MaxNLocator(integer=True))
plt.bar(counts.index, counts.values)
for i, v in enumerate(counts.values):
    plt.text(i, v + 0.1, str(v), ha='center', va='bottom')
plt.xlabel("Definition")
plt.ylabel("Frequency")
plt.title(f"Cluster 1 — Definition Frequency")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

histogram_df = LLM_label.copy()

# Assign cluster IDs based on row order
cluster_size = 50
histogram_df["cluster_number"] = histogram_df.index // cluster_size + 1

# Plot one histogram per cluster
for num, group in histogram_df.groupby("cluster_number"):
    counts = group["definition_key"].value_counts()

    plt.figure(figsize=(6, 4))
    plt.ylim(0, 50)
    plt.gca().yaxis.set_major_locator(mtick.MaxNLocator(integer=True))
    plt.bar(counts.index, counts.values)
    for i, v in enumerate(counts.values):
      plt.text(i, v + 0.1, str(v), ha='center', va='bottom')
    plt.xlabel("Definition Key")
    plt.ylabel("Frequency")
    plt.title(f"Cluster {num} — Definition Frequency")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

import numpy as np

for num, group in histogram_df.groupby("cluster_number"):
    plt.figure(figsize=(6, 4))

    # histogram: bins from 0.0 to 1.0
    bins = np.linspace(0, 1, 11)  # 0.0, 0.1, 0.2, ..., 1.0
    plt.hist(group["confidence"], bins=bins, edgecolor="black", color="skyblue")

    plt.ylim(0, 50)

    plt.xlabel("Confidence Score")
    plt.ylabel("Frequency")
    plt.title(f"Cluster {num} — Confidence Histogram")

    plt.gca().yaxis.set_major_locator(mtick.MaxNLocator(integer=True))

    plt.tight_layout()
    plt.show()